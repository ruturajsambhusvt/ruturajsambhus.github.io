<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html>

<head>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=UA-60320583-2"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'UA-60320583-2');
  </script>

  <title>Ruturaj Sambhus - Home</title>
  <link rel="stylesheet" type="text/css" href="style.css">

  <script type="text/javascript" src="js/hidebib.js"></script>

  <script>
    function showContent() {
      document.getElementById("content").style.display = "block";
    }
  </script>

</head>

<body>

  <div class="section">
    <h1>Ruturaj Sambhus</h1>
  </div>
  <hr>

  <div class="section">
    <table>
      <tr valign="top">
        <td style="width: 620px; vertical-align: top;">
          I am a Graduate Student at Virginia Tech, Blacksburg, VA, in the <a href="https://www.trecvt.org/">Terrestrial
            Robotics
            Engineering and Control Lab</a>, where I have been working on the intersection of Deep Reinforcement
          Learning (DRL), Robotics and Control, advised by <a
            href="https://me.vt.edu/people/faculty/leonessa-alexander.html">Dr. Alexander Leonessa</a> . I worked on
          implementing real-time on-hardware DRL based force control of series elastic actuator, leveraging deadzone for
          faster learning and better sim to real for torque reacher of 7 DOF Panda manipulator, and real-time
          on-hardware velocity reacher for the same robot arm. Please see this
          <a href="https://www.youtube.com/watch?v=f8aTdibnzOw&ab_channel=RuturajSambhus">video</a> for an overview of
          our work.
          <p><br></p>
          Prior to joining Virginia Tech, I was working full-time as a Project Research Associate (Jan'20-Oct'20) and
          Junior Research Fellow
          (Jan'21-Aug'21) at <a href="https://www.iitb.ac.in/">Indian Institute of Technology, Bombay</a>, India, in
          the Robotics Lab on control of haptic virtual interfaces and prosthetic devices with <a
            href="https://www.me.iitb.ac.in/?q=faculty/Prof.%20Abhishek%20Gupta"> Dr. Abhishek Gupta</a>.
          I previously graduated from Indian Institute of
          Technology, Bombay where I completed my Dual Degree Master's research in <a
            href="https://homepages.iitb.ac.in/~ashrivastava.me/People.html">Advanced Manufacturing Process Lab</a>
          advised by <a href="https://www.me.iitb.ac.in/?q=faculty/Prof.%20Amber%20Shrivastava">Dr. Amber
            Shrivastava</a>.
          I worked on modeling, characterization and design of piezoelectric ultrasonic transducers.
          <p><br></p>
          <p>
            <a href="javascript:toggleblock('email')">email</a> | <a
              href="https://scholar.google.com/citations?user=VjqhRxAAAAAJ&hl=en">google scholar</a> | <a
              href="https://www.linkedin.com/in/ruturaj-sambhus-763534a2/"> linkedin </a>
          </p>
          <pre xml:space="preserve" id="email" style="font-size: 12px">

ruturajsambhus AT vt.edu
  </pre>
          <script xml:space="preserve" language="JavaScript">
            hideblock('email');
          </script>
        </td>

        <td width="400"><img src="mi_image.jpeg" alt="My picture" height=250 align="right" /></td>
      </tr>
    </table>
  </div>

  <!-- <div class="section">
    <h2> Research Group</h2>
    <br>
    <table width="90%" width="90%" align="center" border="0" cellspacing="0" cellpadding="8" style="margin-left:15px">
      <tr>
        <td colspan="2">
          Our group is interested in inferring physically and spatially grounded representations from perceptual input,
          and leveraging these for advances in fundamental problems in computer vision and robot manipulation. We
          believe that to enable machines to understand the physical world, we should reduce the reliance on supervision
          by annotation, and instead develop learning mechanisms informed by the real, physical world we live in â€“ by
          incorporating our knowledge about its structure and laws as a 'meta-supervisory' signal.
          <br><br>

          If you are interested in joining our group, please <a href="javascript:toggleblock('prospective')">read
            this</a>.
          <br>
          <br>

          <div id="prospective" class="prospective">
            Dear Prospective Students,<br>
            Thanks for the interest in being a part of our group! Unfortunately, I am unable to reply to individual
            emails, but hope you find the following helpful:


            <br>
            <br>
            <i> I am a CMU student. How do I join your group?</i>
            <br>
            Send me an email and/or drop by my office - I'd be happy to chat! If you are an undergraduate, also consider
            reaching out to the PhD students in our group if their projects align with your interests.

            <br>
            <br>
            <i> I want to join CMU. What graduate programs should I apply to?</i>
            <br>
            PhD. Applicants: While I am primarily affiliated with RI, I can supervise students admitted in any SCS
            department (e.g. MLD, CSD) so apply to the department that best matches your interests and background. If
            you are interested in working with me, mention this in your application statement.

            <br>
            MS Applicants: RI offers <a
              href="https://www.ri.cmu.edu/education/academic-programs/master-of-science-robotics/">MSR</a> (research
            focused) and <a
              href="https://www.ri.cmu.edu/education/academic-programs/master-of-science-robotics/">MSCV</a> (industry
            focused) MS programs among others. Please apply to the program most aligned with your future goals.

            <br>
            <br>
            <i> Should I contact you before applying to CMU for admission?</i>
            <br>
            Admissions across all PhD/MS programs are done by department-level committees and I am unable to help with
            individual applications. Please do feel free to reach out <i>after</i> you are admitted.

            <br>
            <br>
            <i> Are you accepting interns/visitors?</i>
            <br>
            We do not have any short-term positions at this time.


            <br>
          </div>
          <script xml:space="preserve" language="JavaScript">
            hideblock('prospective');
          </script>
          <br>
          <!-- Topics we currently focus on include representation learning, robot learning, reinforcement learning, continual learning, 3D perception, generative modeling, modularity and curiosity-driven learning. 
        </td>
      </tr>
      <tr>
        <td rowspan="1" width="50%">
          <b>PhD Students</b><br>
          <a href="https://homangab.github.io/">Homanga Bharadhwaj</a> (with Abhinav Gupta)<br>
          <a href="https://hzhupku.github.io/">Hanzhe Hu</a><br>
          <a href="https://yehonathanlitman.github.io">Yehonathan Litman</a> (with Fernando De la Torre) <br>
          <a href="https://judyye.github.io/">Yufei (Judy) Ye</a> (with Abhinav Gupta)<br>
          <a href="https://jasonyzhang.com/">Jason Zhang</a> (with Deva Ramanan)
        </td>
        <td>
          <b>MS Students</b><br>
          <a href="https://mayankgrwl97.github.io/">Mayank Agarwal</a> (MSCV)<br>
          <a href="https://thatbrguy.github.io/">Bharath Raj</a> (MSR)<br>
          <a href="https://serverprocessor.wordpress.com/">Naveen Venkat</a> (MSCV)<br>
          <a href="https://www.zhiz.dev/">Zhizhuo (Z) Zhou</a> (MSR)
        </td>
      </tr>
      <tr>
        <td><br></td>
      </tr>
      <tr>
        <td colspan="2"><b>Alumni</b><br>
          <a href="https://yccyenchicheng.github.io/">Yen-Chi Cheng</a> (MSCV)<br>
          <a href="https://paritoshmittal12.github.io/">Paritosh Mittal</a> (MSCV)<br>
        </td>
      </tr>
      <tr>
        <td></td>
      </tr>
    </table>
  </div> -->
  


  <div class="section">
    <h2> Publications (<a href="javascript:showselected()" id="select">selected</a> | <a href="javascript:showall()"
        id="unselect">all</a>) </h2><br>
    <div class="year_heading" data-selected="n"><br>2023
      <hr width="220px" align="left">
    </div>
    <!--------------------------------------------------------------------------->
    <div class="paper" ,id="iros23drlforcesea" data-selected="y">
      <!-- <img class="paper" src="figures/cvpr23sparsefusion.gif" /> -->


      <p> <strong style="color:red">[New]</strong> <b id="papertitle">Real-Time Model-Free Deep Reinforcement Learning
          for Force Control
          of a Series Elastic Actuator</b> <br />
        <strong> Ruturaj Sambhus*,</strong> Aydin Gokce*, Stephen Welch, Connor W. Herron, Alexander Leonessa <br />
        Under Review, IROS 2023 <br />

        <a href="https://arxiv.org/pdf/2304.04911.pdf">pdf </a> &nbsp <a
          href="javascript:toggleblock('iros23drlforceseaBib')">bibtex </a>
      </p>

      <div class="gif"> <iframe src="https://giphy.com/embed/ACUnOg88XJLxSIsnkP" width="480*0.3" height="270*0.3"
          frameBorder="0" class="giphy-embed" allowFullScreen></iframe>
        <p><a href="https://giphy.com/gifs/ACUnOg88XJLxSIsnkP">via GIPHY</a></p>
      </div>
      <div class="gif"><iframe src="https://giphy.com/embed/Gng8DKGWwjqVPfIVwh" width="480*0.3" height="270*0.3"
          frameBorder="0" class="giphy-embed" allowFullScreen></iframe>
        <p><a href="https://giphy.com/gifs/Gng8DKGWwjqVPfIVwh">via GIPHY</a></p>
      </div>

      <div class="papermeta" id="iros23drlforceseaMeta">
        <pre xml:space="preserve" id="iros23drlforceseaBib">


        @misc{sambhus2023realtime,
          title={Real-Time Model-Free Deep Reinforcement Learning for Force Control of a Series Elastic Actuator}, 
          author={Ruturaj Sambhus and Aydin Gokce and Stephen Welch and Connor W. Herron and Alexander Leonessa},
          year={2023},
          eprint={2304.04911},
          archivePrefix={arXiv},
          primaryClass={cs.LG}
          }</pre>
        </td>
        <script language="javascript" type="text/javascript" xml:space="preserve">
          hideblock('iros23drlforceseaBib');
        </script>
      </div>
    </div>
    <!--------------------------------------------------------------------------->

    <!--------------------------------------------------------------------------->
    
    <div class="paper" id="imece23drlseaposition" data-selected="y">
      <!-- <img class="paper" src="figures/cvpr23affordance.gif" /> -->
      <p> <strong style="color:red">[New]</strong> <b id="papertitle">
          Real-World Deep Reinforcement Learning for Position Tracking of a Pendulum Driven by a Series Elastic
          Actuator</b> <br />
        <strong>Ruturaj Sambhus*</strong>, Aydin Gokce*, Stephen Welch*, Alexander Leonessa <br />
        Accepted, IMECE, 2023 <br />
        <!-- <a href="https://arxiv.org/pdf/2303.12538">pdf </a> &nbsp <a
        href="https://judyye.github.io/affordiffusion-www/">project page </a> &nbsp <a
        href="javascript:toggleblock('cvpr23affordanceBib')">bibtex </a> -->
      </p>
      <img class="imece" src="figures/imece_tracking_new.png" />
      <div class="papermeta" id="imece23drlseapositionMeta">
        <pre xml:space="preserve" id="imece23drlseapositionBib">

<!-- @inproceedings{ye2023affordance,
  title={Affordance Diffusion: Synthesizing Hand-Object Interactions}, 
  author={Yufei Ye and Xueting Li and Abhinav Gupta  and Shalini De Mello  and Stan Birchfield, Jiaming Song and Shubham Tulsiani and Sifei Liu},
  booktitle={CVPR},
  year={2023}
} -->
</pre>
        </td>
        <script language="javascript" type="text/javascript" xml:space="preserve">
          hideblock('imece23drlseapositionBib');
        </script>
      </div>
    </div>



    <!--------------------------------------------------------------------------->
    <!-- New Section Projects -->
    <!--------------------------------------------------------------------------->
  </div>

  <div class="section">
    <h2> Projects (<a href="javascript:showselected()" id="select">selected</a> | <a href="javascript:showall()"
        id="unselect">all</a>) </h2><br>
    <div class="year_heading" data-selected="n"><br>2023
      <hr width="220px" align="left">
    </div>
    <!--------------------------------------------------------------------------->


    <div class="paper" id="drlseaprojects" data-selected="y">

      <p> <b id="papertitle">Deep Reinforcement Learning (DRL) for Force Control of Series Elastic Actuator</b> <br />

      </p>

      <p>Terrestrial Robotics Engineering and Controls (TREC) Lab, Virginia Tech, Blacksburg</p>

      <div class="gif"> <iframe src="https://giphy.com/embed/ACUnOg88XJLxSIsnkP" width="480*0.3" height="270*0.3"
          frameBorder="0" class="giphy-embed" allowFullScreen></iframe>
        <p><a href="https://giphy.com/gifs/ACUnOg88XJLxSIsnkP">via GIPHY</a></p>
      </div>
      <div class="gif"><iframe src="https://giphy.com/embed/Gng8DKGWwjqVPfIVwh" width="480*0.3" height="270*0.3"
          frameBorder="0" class="giphy-embed" allowFullScreen></iframe>
        <p><a href="https://giphy.com/gifs/Gng8DKGWwjqVPfIVwh">via GIPHY</a></p>
      </div>

      <!-- <ul>
        <li> <b>Objective:</b> To develop a real-time model-free DRL algorithm for force control of a series elastic
          actuator (SEA) driving a pendulum. </li>
        <li> <b>Approach:</b> We use a DRL algorithm to learn the optimal policy for force control of the SEA. The
          algorithm is model-free and does not require any prior knowledge of the system dynamics. </li>
        <li> <b>Results:</b> The DRL algorithm is able to learn the optimal policy for force control of the SEA. The
          algorithm is able to track the desired force trajectory with minimal error. </li>

      </ul> -->


      <h3>Objective:</h3>
      <p>The objective of the project was to apply deep reinforcement learning (DRL) techniques to develop a force
        control strategy for a series elastic actuator (SEA) driving a pendulum system. The focus was on using data to addressing
        nonlinearities, such as difficult to identify stiction and backlash, to achieve accurate force trajectory tracking.</p>

      <h4>Approach and Results:</h4>

      <h3>1. Problem Conceptualization:</h3>
      <ul>
        <li>Formulated the reinforcement learning (RL) problem for force trajectory tracking of a pendulum driven by a
          series elastic actuator.</li>
        <li>Considered the presence of nonlinearities, specifically stiction and backlash, in the system.</li>
        <li>Published a paper on <a href="https://arxiv.org/">arXiv</a> discussing the conceptualization of the RL
          problem.</li>
      </ul>

      <h3>2. Integration of DRL and IHMC Toolbox:</h3>
      <ul>
        <li>Collaborated with a senior undergraduate student to integrate Python-based DRL using Ray RLlib with the
          Java-based IHMC toolbox.</li>
        <li>Established networking between the DRL framework and the IHMC toolbox using socket communication (UDP/TCP).
        </li>
      </ul>

      <h3>3. Engineering the RL Environment:</h3>
      <ul>
        <li>Engineered the RL environment to ensure safety limits for the system, specifically bounded joint positions,
          to keep the pendulum within safe limits during learning episodes.</li>
      </ul>

      <h3>4. Hardware Learning and Performance:</h3>
      <ul>
        <li>Successfully achieved hardware learning for force trajectory tracking up to a frequency of 0.35 Hz.</li>
        <li>Evaluated the performance using mean absolute error on a chirp signal.</li>
        <li>Demonstrated that the DRL approach outperformed a traditional PID controller by approximately 50% in terms
          of mean absolute error.</li>
        <li>Ensured stability of the system throughout the learning process, avoiding any instability issues.</li>
      </ul>

      <p>Overall, the research project focused on applying deep reinforcement learning techniques to address force
        control challenges in a series elastic actuator driving a pendulum system. The integration of DRL with the IHMC
        toolbox and engineering of the RL environment resulted in successful hardware learning and improved performance
        compared to a PID controller.</p>

      </td>
      <script language="javascript" type="text/javascript" xml:space="preserve">
        hideblock('iros23drlforceseaBib');
      </script>
    </div>

    <!--------------------------------------------------------------------------->

    <!--------------------------------------------------------------------------->
    <div class="year_heading" data-selected="n"><br>2022
      <hr width="220px" align="left">
    </div>
    <div class="paper" data-selected="y">
      <!-- <img class="paper" src="figures/cvpr23sparsefusion.gif" /> -->


      <p> <b id="papertitle">Deep Reinforcement Learning (DRL) for Real Robotic Arm Control</b> <br />

      </p>
      <p>Terrestrial Robotics Engineering and Controls (TREC) Lab, Virginia Tech, Blacksburg</p>


      <div class="gif"> <iframe src="https://giphy.com/embed/zR6clp5PCishzyeJns" width="480*0.3" height="270*0.3"
          frameBorder="0" class="giphy-embed" allowFullScreen></iframe>
        <p><a href="https://giphy.com/gifs/zR6clp5PCishzyeJns">via GIPHY</a></p>
      </div>
      <div class="gif"><iframe src="https://giphy.com/embed/Gng8DKGWwjqVPfIVwh" width="480*0.3" height="270*0.3"
          frameBorder="0" class="giphy-embed" allowFullScreen></iframe>
        <p><a href="https://giphy.com/gifs/Gng8DKGWwjqVPfIVwh">via GIPHY</a></p>
      </div>

      <!-- <ul>
      <li> <b>Objective:</b> To develop a real-time model-free DRL algorithm for force control of a series elastic
        actuator (SEA) driving a pendulum. </li>
      <li> <b>Approach:</b> We use a DRL algorithm to learn the optimal policy for force control of the SEA. The
        algorithm is model-free and does not require any prior knowledge of the system dynamics. </li>
      <li> <b>Results:</b> The DRL algorithm is able to learn the optimal policy for force control of the SEA. The
        algorithm is able to track the desired force trajectory with minimal error. </li>

    </ul> -->


      <h3>Objective:</h3>
      <p>The objective of the project was to achieve stable hardware learning performance for a 7-degree-of-freedom
        (DOF)
        velocity reacher task and torque reacher on a Franka Emika Panda robot arm. The task involved controlling the
        task
        space position by
        using joint velocities and joint torques as actions respectively.</p>

      <h3>Approach and Results:</h3>
      <h3>1. Safety Bounds on Robot:</h3>
      <ul>
        <li>Prioritized safe operation for velocity control by limiting the exploration through constrained observation
          space and action limits for velocity and torque control</li>
      </ul>


      <h3>2. Implementation of Velocity Control:</h3>
      <ul>
        <li>Extended the PyBullet based Panda robot class to a gym based DRL environment, trained a velocity reacher in
          simulation</li>
        <li>Expanded the gym environment to control a real Panda arm and achieved from scratch DRL learned policies with
          safety </li>
      </ul>

      <h3>3. Implementation of Torque Control:</h3>
      <ul>
        <li>Extended the existing low-level C++ code to incorporate torque control during the task and velocity control
          for reset, since reseting with torques would have needed a custom torque controller design due to joint
          friction.</li>
        <li>Implemented a torque control-based 7-DOF reacher task using the PyBullet Physics Engine, trained using
          Stable
          Baselines 3 and Ray RLlib PPO and SAC algorithms.</li>
        <!-- <li>Hardware learning was observed to take long times and run into communication issues</li> -->
      </ul>

      <h3>4. Sim-to-Real Transfer:</h3>
      <ul>
        <li>Estimated the joint friction by approximating with the deadzone in joint torque action space.</li>

        <li>Utilized the PyBullet Physics Engine to model the estimated friction and ensure a seamless transfer without
          requiring explicit sim-to-real
          techniques.</li>
      </ul>


      <p>Overall, the project focused on achieving stable hardware learning performance for a 7-DOF velocity reacher
        task
        on the Franka Emika Panda robot arm. The low-level C++ code extension enabled torque control during the task,
        while velocity control was used for reset. By implementing a torque control-based reacher task and utilizing the
        PyBullet Physics Engine, the project achieved successful sim-to-real transfer without requiring specific
        techniques for this purpose. Additionally, joint friction estimation was performed to improve the accuracy and
        realism of the simulation-to-real transfer.</p>



      </td>
      <script language="javascript" type="text/javascript" xml:space="preserve">
        hideblock('iros23drlforceseaBib');
      </script>
    </div>
  </div>




  <div class="paper" id="imece23drlseaposition" data-selected="y">
    <!-- <img class="paper" src="figures/cvpr23affordance.gif" /> -->
    <p> <strong style="color:red">[New]</strong> <b id="papertitle">
        Real-World Deep Reinforcement Learning for Position Tracking of a Pendulum Driven by a Series Elastic
        Actuator</b> <br />
      <strong>Ruturaj Sambhus*</strong>, Aydin Gokce*, Stephen Welch*, Alexander Leonessa <br />
      Accepted, IMECE, 2023 <br />
      <!-- <a href="https://arxiv.org/pdf/2303.12538">pdf </a> &nbsp <a
        href="https://judyye.github.io/affordiffusion-www/">project page </a> &nbsp <a
        href="javascript:toggleblock('cvpr23affordanceBib')">bibtex </a> -->
    </p>
    <img class="imece" src="figures/imece_tracking_new.png" />
    <div class="papermeta" id="imece23drlseapositionMeta">
      <pre xml:space="preserve" id="imece23drlseapositionBib">

<!-- @inproceedings{ye2023affordance,
  title={Affordance Diffusion: Synthesizing Hand-Object Interactions}, 
  author={Yufei Ye and Xueting Li and Abhinav Gupta  and Shalini De Mello  and Stan Birchfield, Jiaming Song and Shubham Tulsiani and Sifei Liu},
  booktitle={CVPR},
  year={2023}
} -->
</pre>
      </td>
      <script language="javascript" type="text/javascript" xml:space="preserve">
        hideblock('cvpr23affordanceBib');
      </script>
    </div>
  </div>


  <!--------------------------------------------------------------------------->

  <!--------------------------------------------------------------------------->
  <div class="paper" id="iclr20motor" data-selected="n">
    <img class="paper" src="figures/iclr20motor.png" />
    <p><b id="papertitle">Discovering Motor Programs by Recomposing Demonstrations</b> <br />
      Tanmay Shankar, <strong>Shubham Tulsiani</strong>, Lerrel Pinto, Abhinav Gupta <br />
      ICLR, 2020 <br />
      <a href="https://openreview.net/pdf?id=rkgHY0NYwr">pdf </a> &nbsp <a
        href="javascript:toggleblock('iclr20motorBib')">bibtex </a>
    </p>
    <div class="papermeta" id="iclr20motorMeta">
      <pre xml:space="preserve" id="iclr20motorBib">

@inproceedings{shankar20motor,
  title={Discovering Motor Programs by Recomposing Demonstrations},
  author={Shankar, Tanmay and Tulsiani, Shubham and Pinto, Lerrel and Gupta, Abhinav},
  booktitle={ICLR},
  year={2020}
}</pre>
      </td>
      <script language="javascript" type="text/javascript" xml:space="preserve">
        hideblock('iclr20motorBib');
      </script>
    </div>
  </div>
  <!--------------------------------------------------------------------------->

  <!--------------------------------------------------------------------------->
  <div class="paper" id="icra20schema" data-selected="n">
    <img class="paper" src="figures/icra20schema.png" />
    <p><b id="papertitle">Efficient Bimanual Manipulation using Learned Task Schemas</b> <br />
      Rohan Chitnis, <strong>Shubham Tulsiani</strong>, Saurabh Gupta, Abhinav Gupta <br />
      ICRA, 2020 <br />
      <a href="https://arxiv.org/pdf/1909.13874.pdf">preprint </a> &nbsp <a
        href="javascript:toggleblock('icra20schemaBib')">bibtex </a> &nbsp <a
        href="https://www.youtube.com/watch?v=TBUEHk37a64">video </a>
    </p>
    <div class="papermeta" id="icra20schemaMeta">
      <pre xml:space="preserve" id="icra20schemaBib">

@inproceedings{chitnis20schema,
  title={Efficient Bimanual Manipulation Using Learned Task Schemas},
  author={Chitnis, Rohan and Tulsiani, Shubham and Gupta, Saurabh and Gupta, Abhinav},
  booktitle={ICRA},
  year={2020}
}</pre>
      </td>
      <script language="javascript" type="text/javascript" xml:space="preserve">
        hideblock('icra20schemaBib');
      </script>
    </div>
  </div>
  <!--------------------------------------------------------------------------->
  <div class="year_heading" data-selected="n"><br>2019
    <hr width="220px" align="left">
  </div>
  <!--------------------------------------------------------------------------->
  <div class="paper" id="corl19ocm" data-selected="n">
    <img class="paper" src="figures/corl19ocm.png" />
    <p><b id="papertitle">Object-centric Forward Modeling for Model Predictive Control</b> <br />
      Yufei Ye, Dhiraj Gandhi, Abhinav Gupta, <strong>Shubham Tulsiani</strong> <br />
      CORL, 2019 <br />
      <a href="https://arxiv.org/pdf/1910.03568.pdf">pdf </a> &nbsp <a href="https://judyye.github.io/ocmpc/">project
        page </a> &nbsp <a href="javascript:toggleblock('corl19ocmBib')">bibtex </a>
    </p>
    <div class="papermeta" id="corl19ocmMeta">
      <pre xml:space="preserve" id="corl19ocmBib">

@inProceedings{ye2019ocm,
  title={Object-centric Forward Modeling for Model Predictive Control},
  author={Ye, Yufei and Gandhi, Dhiraj and Gupta, Abhinav and Tulsiani, Shubham},
  year={2019},
  booktitle={Conference on Robot Learning (CORL)}
}</pre>
      </td>
      <script language="javascript" type="text/javascript" xml:space="preserve">
        hideblock('corl19ocmBib');
      </script>
    </div>
  </div>




  <!--------------------------------------------------------------------------->
  <div class="year_heading" data-selected="n"><br>2013
    <hr width="220px" align="left">
  </div>
  <!--------------------------------------------------------------------------->
  <div class="paper" id="uist13colors" data-selected="n">
    <img class="paper" src="figures/uist13.png" />
    <p><b id="papertitle">A colorful approach to text processing by example</b> <br />
      Kuat Yessenov, <strong>Shubham Tulsiani</strong>, Aditya Menon, Robert C Miller, Sumit Gulwani, Butler Lampson,
      Adam Kalai <br />
      UIST, 2013 <br />
      <a href="papers/uist13colors.pdf">pdf </a> &nbsp <a href="javascript:toggleblock('uist13colorsBib')">bibtex </a>
    </p>
    <div class="papermeta" id="uist13colorsMeta">
      <pre xml:space="preserve" id="uist13colorsBib">

@inproceedings{yessenov2013colorful,
  title={A colorful approach to text processing by example},
  author={Yessenov, Kuat and
  Tulsiani, Shubham and
  Menon, Aditya and
  Miller, Robert C and
  Gulwani,Sumit and
  Lampson, Butler and
  Kalai, Adam},
  booktitle={UIST},
  pages={495--504},
  year={2013},
  organization={ACM}
}</pre>
      </td>
      <script language="javascript" type="text/javascript" xml:space="preserve">
        hideblock('uist13colorsBib');
      </script>
    </div>
  </div>

  <!--------------------------------------------------------------------------->

  <script language="javascript" type="text/javascript" xml:space="preserve">
    showselected()</script>

<!--------------------------------------------------------------------------->


  <!--------------------------------------------------------------------------->
  <!--- TEMPLATE
<div class="paper" id="paperId">
  <img class="paper" title="X" src="images/X.png" />
  <p><b id="papertitle">Title</b> <br/>
  <strong>Shubham Tulsiani</strong>, Richard Tucker, Noah Snavely<br />
  ECCV, 2018<br />
  <a href="link">pdf</a>  &nbsp <a href="page">project page</a>  &nbsp <a href="javascript:toggleblock('paperIdAbs')">abstract</a> &nbsp <a href="javascript:toggleblock('paperIdBib')">bibtex</a>  &nbsp <a href="codelink">code</a> </p>

  <div class="papermeta" id="paperIdMeta">
  <em id="paperIdAbs">ABSTRACT</em></p>
  <pre xml:space="preserve" id="paperIdBib" style="font-size: 12px">
@inProceedings{
BIBTEX
}</pre></td>
  <script language="javascript" type="text/javascript" xml:space="preserve">
     hideblock('paperIdAbs');
     hideblock('paperIdBib');
  </script>
  </div>
</div>

-->
  <!--------------------------------------------------------------------------->

  </div>

  <div class="section">
    <h2> Teaching</h2>

    <br>
    <table width="90%" width="90%" align="center" border="0" cellspacing="0" cellpadding="8" style="margin-left:15px">
      <tr>
        <td colspan="2">
          <a href="https://geometric3d.github.io/">16-822: Geometry-based Methods in Vision</a>. Fall 2022 <br>
          <a href="https://learning3d.github.io/">16-825: Learning for 3D Vision</a>. Spring 2022, Spring 2023
        </td>
      </tr>
    </table>

    <br>
  </div>

</body>

</html>